{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6b6yXAsi-u7",
        "outputId": "4c6f6aa5-4a57-4030-c1e4-550eb0bfb199"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1688/1688 [==============================] - 21s 11ms/step - loss: 0.4909 - accuracy: 0.8262 - val_loss: 0.3818 - val_accuracy: 0.8593\n",
            "Epoch 2/10\n",
            "1688/1688 [==============================] - 11s 7ms/step - loss: 0.3701 - accuracy: 0.8647 - val_loss: 0.3529 - val_accuracy: 0.8715\n",
            "Epoch 3/10\n",
            "1688/1688 [==============================] - 10s 6ms/step - loss: 0.3315 - accuracy: 0.8789 - val_loss: 0.3845 - val_accuracy: 0.8633\n",
            "Epoch 4/10\n",
            "1688/1688 [==============================] - 12s 7ms/step - loss: 0.3074 - accuracy: 0.8866 - val_loss: 0.3270 - val_accuracy: 0.8810\n",
            "Epoch 5/10\n",
            "1688/1688 [==============================] - 12s 7ms/step - loss: 0.2884 - accuracy: 0.8924 - val_loss: 0.3484 - val_accuracy: 0.8752\n",
            "Epoch 6/10\n",
            "1688/1688 [==============================] - 11s 7ms/step - loss: 0.2718 - accuracy: 0.8991 - val_loss: 0.3387 - val_accuracy: 0.8863\n",
            "Epoch 7/10\n",
            "1688/1688 [==============================] - 12s 7ms/step - loss: 0.2606 - accuracy: 0.9036 - val_loss: 0.3381 - val_accuracy: 0.8757\n",
            "Epoch 8/10\n",
            "1688/1688 [==============================] - 12s 7ms/step - loss: 0.2493 - accuracy: 0.9071 - val_loss: 0.3214 - val_accuracy: 0.8822\n",
            "Epoch 9/10\n",
            "1688/1688 [==============================] - 13s 8ms/step - loss: 0.2373 - accuracy: 0.9112 - val_loss: 0.3130 - val_accuracy: 0.8873\n",
            "Epoch 10/10\n",
            "1688/1688 [==============================] - 12s 7ms/step - loss: 0.2297 - accuracy: 0.9140 - val_loss: 0.3208 - val_accuracy: 0.8862\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3485 - accuracy: 0.8810\n",
            "Test loss: 0.3485, Test accuracy: 0.8810\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Load the Fashion MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalize the pixel values to range [0, 1]\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# Reshape the data to 1D arrays (28x28 images flattened to 784-length vectors)\n",
        "X_train = X_train.reshape(-1, 784)\n",
        "X_test = X_test.reshape(-1, 784)\n",
        "\n",
        "# One-hot encode the labels\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "y_train_onehot = encoder.fit_transform(y_train.reshape(-1, 1))\n",
        "y_test_onehot = encoder.transform(y_test.reshape(-1, 1))\n",
        "\n",
        "# Neural Network architecture\n",
        "input_size = 784\n",
        "hidden_size = 256\n",
        "output_size = 10\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(hidden_size, activation='relu', input_shape=(input_size,)),\n",
        "    tf.keras.layers.Dense(output_size, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "model.fit(X_train, y_train_onehot, epochs=epochs, batch_size=batch_size, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(X_test, y_test_onehot)\n",
        "print(f'Test loss: {loss:.4f}, Test accuracy: {accuracy:.4f}')\n"
      ]
    }
  ]
}
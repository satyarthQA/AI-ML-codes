# -*- coding: utf-8 -*-
"""Stock_closing_price_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uayeBfjVExSAYvMZU3ksTxjJq-sRyv6A
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
import keras
from keras.layers import LSTM
from keras.models import Sequential
from keras.layers import TimeDistributed
from keras.layers import Dense, Activation, Dropout
from sklearn.model_selection import TimeSeriesSplit
from tensorflow.keras.utils import plot_model
from sklearn.preprocessing import MinMaxScaler

# loading the data set
from google.colab import files
uploaded = files.upload()

import io

df = pd.read_csv(io.BytesIO(uploaded['yahoo_stock.csv']))
df

df.iloc[1660]

# Checking whether empty values exist
df.isnull().sum()

features = ["Close", "High", "Low", "Volume"]
# target variable
target = pd.DataFrame(df["Open"])
target

scaler = MinMaxScaler()# to scale data between 0 and 1
feature_transform = scaler.fit_transform(df[features])# this will convert the scaled data frame to numpy array
feature_transform= pd.DataFrame(columns=features, data=feature_transform, index=df.index)# this will convert above numpy array to scaled data frame
feature_transform.head()# to show first 5 rows
target_transform = scaler.fit_transform(target)#same explanation for as in line-2
target_variable= pd.DataFrame(target_transform, columns=['Adj Close'])
target_variable

timesplit= TimeSeriesSplit(n_splits=10)# it is used for time series cross-validation.
#In this snippet, the TimeSeriesSplit object is initialized with a specified number of splits (10 in this case).
#The time series split ensures the test datasets are younger or later than train datasets, which is more realistic since we will not be able to train on “future” data.

for train_index, test_index in timesplit.split(feature_transform):# split the data set into training and testing set.
        X_train, X_test = feature_transform[:len(train_index)], feature_transform[len(train_index): (len(train_index)+len(test_index))]
        y_train, y_test = target_variable[:len(train_index)].values.ravel(), target_variable[len(train_index): (len(train_index)+len(test_index))].values.ravel()

X_train

trainX =np.array(X_train)# for converting in Numpy array.
testX =np.array(X_test)
X_train = trainX.reshape(X_train.shape[0], 1, X_train.shape[1])
#It changes the shape of X_train from (number_of_samples, number_of_features) to (number_of_samples, 1, number_of_features).
# The extra dimension of size 1 is added to indicate the time steps for each sample.
#In a time series context, this typically represents the sequence length.
X_test = testX.reshape(X_test.shape[0], 1, X_test.shape[1])

import tensorflow as tf
tf.random.set_seed(42)

# creating LSTM model
lstm = Sequential()
lstm.add(LSTM(units=50,return_sequences = True,input_shape = (X_train.shape[1],4),activation='relu'))
#Adding the first LSTM layer to the model. It has 50 units (neurons), returns sequences

lstm.add(Dropout(0.2))
 #Adding a dropout layer with a dropout rate of 0.2 after the first LSTM layer.
 #Dropout is a regularization technique used to prevent overfitting by randomly dropping a fraction of the units during training.

lstm.add(LSTM(units=60,return_sequences = True,input_shape = (X_train.shape[1],4),activation='relu'))
#Adding the second LSTM layer with 60 units, returning sequences, and using ReLU activation.
lstm.add(Dropout(0.3))

lstm.add(LSTM(units=80,return_sequences = True,input_shape = (X_train.shape[1],4),activation='relu'))
#Adding the third LSTM layer with 60 units, returning sequences, and using ReLU activation.
lstm.add(Dropout(0.4))

lstm.add(LSTM(units=120,activation='relu',return_sequences= False))
#Adding the fourth LSTM layer with 120 units, without returning sequences
#When set to False, this parameter indicates that the LSTM layer should only return the output at the final time step.
lstm.add(Dropout(0.5))

lstm.add(Dense(units=1))
# a dense layer with 1 unit is added. This is the output layer of our model.
#In time series forecasting tasks, it's common to have a single output unit for regression.

lstm.compile(optimizer='adam',
             loss='mean_squared_error',
             metrics=['RootMeanSquaredError'])
# compiling our LSTM model with the Adam optimizer and mean squared error as the loss function.

lstm.summary()
#It provides information about each layer in our model, including the layer type, output shape, and the number of parameters.

lstm.fit(X_train, y_train,epochs=100,batch_size=32)
#X_train: The input training data (sequences).
#y_train: The target training data (labels or values to predict).
#epochs=100: The number of training epochs. This determines how many times the model will go through the entire training dataset during training.
#batch_size=32: This determines how many samples are used in each forward and backward pass of the model during each epoch.

y_pred= lstm.predict(X_test)

plt.plot(y_test, label="True Value")
plt.plot(y_pred, label="LSTM Value")
plt.title('Prediction by LSTM')
plt.xlabel("Time Scale")
plt.ylabel("Stock price")
plt.legend()
plt.show()
#The graph is for comparing test data with predicted values

from sklearn.metrics import mean_absolute_error
mae_LSTM= mean_absolute_error(y_test, y_pred)
print("Mean Absolute Error:", mae_LSTM)

from keras.layers import SimpleRNN

 #  initializing the RNN model
regressor = Sequential()

#  adding RNN layers and dropout regularization
regressor.add(SimpleRNN(units = 50,
                        activation = "tanh",
                        return_sequences = True,
                        input_shape = (X_train.shape[1],4)))
regressor.add(Dropout(0.2))

regressor.add(SimpleRNN(units = 50,
                        activation = "tanh",
                        return_sequences = True))

regressor.add(SimpleRNN(units = 50,
                        activation = "tanh",
                        return_sequences = True))

regressor.add( SimpleRNN(units = 50))

# adding the output layer
regressor.add(Dense(units = 1,activation='linear'))

# compiling RNN
regressor.compile(optimizer='adam',
             loss='mean_squared_error',
             metrics=['RootMeanSquaredError'])

#  fitting the model
regressor.fit(X_train, y_train, epochs = 20, batch_size = 2)
regressor.summary()

y_pred_RNN= regressor.predict(X_test)
# predicting y values based on testing data set.

plt.plot(y_test, label="True Value")
plt.plot(y_pred_RNN, label="RNN Value")
plt.title('Prediction by RNN')
plt.xlabel("Time Scale")
plt.ylabel("Stock price")
plt.legend()
plt.show()
#The graph is for comparing test data with predicted values

mae_RNN= mean_absolute_error(y_test, y_pred_RNN)
print("Mean Absolute Error:", mae_RNN)



"""**Conclusion**- *If we compare LSTM and RNN model accuracy on the basis of mean absolute error , we can conclude that LSTM is better predictor than RNN as mean absolute error of LSTM model(which is 0.022) is less than that of RNN (which is 0.033)*"""